{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Language Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "osKgPaDwhaN4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"\"\"\\ncsv.py - read/write/investigate CSV files\\n\"\"\"\\n\\nimport re\\nfrom _csv import Error, __version__, w'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "data = open(csv.__file__).read()\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16144])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.tensor(\n",
    "    [ord(c) for c in data])\n",
    "data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = data_tensor.max() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Feedforward/MLP Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily embed input vector in a bigger space and chop off all negative components\n",
    "def MLP(emb_dim, hid_dim): # or called feed-forward network dimension \n",
    "    # internal logic -> same dimensionality \n",
    "    return nn.Sequential(\n",
    "        nn.Linear(emb_dim, hid_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hid_dim, emb_dim)\n",
    "    ) # make us a sequential layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Single Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_dim, head_dim):\n",
    "        super().__init__()\n",
    "        self.get_query = nn.Linear(emb_dim, head_dim)\n",
    "        self.get_key = nn.Linear(emb_dim, head_dim)\n",
    "        self.get_value = nn.Linear(emb_dim, head_dim)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        seq_len, emb_dim = x.shape\n",
    "        \n",
    "        # get the query vector\n",
    "        q = self.get_query(x)\n",
    "        assert q.shape == (seq_len, head_dim)\n",
    "        \n",
    "        # get the key vector\n",
    "        k = self.get_key(x)\n",
    "        assert k.shape == (seq_len, head_dim)\n",
    "        \n",
    "        # get the value vector\n",
    "        v = self.get_value(x)\n",
    "        assert v.shape == (seq_len, head_dim)\n",
    "        \n",
    "        # invert the key vector\n",
    "        k_trans = torch.t(k)\n",
    "        assert k_trans.shape == (head_dim, seq_len)\n",
    "        # compute the similarity between the query and key to get the attention weights\n",
    "        similarity = q @ k_trans\n",
    "        assert similarity.shape == (seq_len, seq_len)\n",
    "        \n",
    "        # scale the weights and apply softmax\n",
    "        scaled_similarity = similarity / (head_dim ** .5)\n",
    "        attention_weights = scaled_similarity.softmax(dim=1)\n",
    "        assert attention_weights.shape == (seq_len, seq_len)\n",
    "        \n",
    "        # return a value matrix that takes into account the attentions\n",
    "        return attention_weights @ v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_dim, head_dim, num_heads):\n",
    "        super().__init__()\n",
    "        # create multiple attention layers (depending on num_heads)\n",
    "        self.heads = nn.ModuleList([\n",
    "            SingleHeadAttention(emb_dim, head_dim) for i in range(num_heads)\n",
    "        ])\n",
    "        \n",
    "        # convert to a format that can be taken in by the MLP\n",
    "        self.to_output = nn.Linear(num_heads*head_dim, emb_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get the outputs from the different attention heads\n",
    "        head_outputs = [head(x) for head in self.heads]\n",
    "        # aggregate the outputs from each attention head\n",
    "        heads_combined = torch.cat(head_outputs, dim=-1)\n",
    "        # print(f\"heads_combined = {heads_combined.shape}\") 50 x 30\n",
    "        # change to a format that can be taken in by the next layer\n",
    "        out = self.to_output(heads_combined)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Transformer` layer consists of the multi-head attention layer and the MLP layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTransformerLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, head_dim, num_heads, feedforward_dim):\n",
    "        super().__init__()\n",
    "        # define multi-head self attention layer\n",
    "        self.multihead_self_attn = MultiHeadAttention(embed_dim, head_dim, num_heads)\n",
    "        # define feedforward layer\n",
    "        self.feedforward = MLP(emb_dim, feedforward_dim)\n",
    "        \n",
    "        # For viewing the number of in & out states after going through each layer\n",
    "        self.norm_after_atten = nn.LayerNorm(emb_dim)\n",
    "        self.norm_after_feedforward = nn.LayerNorm(emb_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 1) go through the attention layer\n",
    "        x = self.multihead_self_attn(x)\n",
    "        x = self.norm_after_atten(x)\n",
    "        # 2) go through the MLP layer\n",
    "        x = self.feedforward(x)\n",
    "        x = self.norm_after_feedforward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, embed_dim, head_dim, fdfw_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.word_to_embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        # self.pos_to_embedding = nn.Embedding(max_len, embed_dim)\n",
    "        self.model = SingleTransformerLayer(embed_dim, head_dim, num_heads, fdfw_dim)\n",
    "        self.lm_head = nn.Linear(emb_dim, vocab_size, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # get the word embeddings\n",
    "        x = self.word_to_embedding(x)\n",
    "        # get the position embeddings\n",
    "        # position_ids = torch.arrange(input_ids.shape[-1])\n",
    "        # pos_embeddings = self.pos_to_embedding(position_ids)\n",
    "        \n",
    "        #x = word_embeddings + pos_embeddings\n",
    "        x = self.model(x)\n",
    "        \n",
    "        return self.lm_head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 3\n",
    "emb_dim = 5\n",
    "head_dim = emb_dim // num_heads\n",
    "d_feed_forward = emb_dim * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(vocab_size=vocab_size, max_len=50, embed_dim=emb_dim, head_dim=head_dim, fdfw_dim=d_feed_forward, num_heads=num_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# optimizer\n",
    "optimizer = SGD(model.parameters(), lr=.05)\n",
    "\n",
    "seq_length = 50\n",
    "\n",
    "losses = []\n",
    "# one epoch = one complete pass\n",
    "# not doing epochs not.. take random samples\n",
    "for batch_idx in range(1000): \n",
    "    # get one batch or data\n",
    "    start_at = 0 #random.randrange(size - sequence_length - 1)\n",
    "    input_ids = data_tensor[start_at:start_at+seq_length]\n",
    "    #print(input_ids)\n",
    "    targets = data_tensor[start_at + 1:start_at + 1 + seq_length]\n",
    "    #print(targets)\n",
    "    \n",
    "    # give the data to the model, ask for predictions\n",
    "    logits = model(input_ids)\n",
    "    \n",
    "    # compute loss\n",
    "    loss = F.cross_entropy(logits, targets)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    # step the optimizer\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "pd.Series(losses).ewm(alpha = .01).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNS7mRS03a7VSFcbdUnYf/k",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "012-tokenization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
